import sqlite3
from contextlib import contextmanager
import pycountry
import pandas as pd


class SqlManager:
    def __init__(self, db_path_1="000malware.db", db_path_2="001malware.db"):
        self.db_path_1 = db_path_1
        self.db_path_2 = db_path_2
        self.active_db = self.db_path_1  # Start with the first database as active

    @contextmanager
    def db_cursor(self):
        """
        Context manager to handle the SQLite cursor. It automatically closes the connection
        after the block of code within the 'with' statement is executed.
        """
        conn = sqlite3.connect(self.active_db)
        cursor = conn.cursor()
        try:
            yield cursor
        finally:
            conn.commit()
            cursor.close()
            conn.close()

    def switch_database(self):
        """
        Switch the active database between the first and second database.
        """
        self.active_db = self.db_path_1 if self.active_db == self.db_path_2 else self.db_path_2

    def fetch_all_services(self):
        data = []
        with self.db_cursor() as cursor:
            cursor.execute("SELECT * FROM services")
            data = cursor.fetchall()
        self.switch_database()
        with self.db_cursor() as cursor:
            cursor.execute("SELECT * FROM services")
            data += cursor.fetchall()

        return data

    def fetch_all_domains(self):
        data = []
        with self.db_cursor() as cursor:
            cursor.execute("SELECT * FROM domains")
            data = cursor.fetchall()
        self.switch_database()
        with self.db_cursor() as cursor:
            cursor.execute("SELECT * FROM domains")
            data = cursor.fetchall()
        return data

    def fetch_all_summary(self):
        with self.db_cursor() as cursor:
            cursor.execute("SELECT * FROM summary")
            return cursor.fetchall()

    def fetch_all_counts(self):
        with self.db_cursor() as cursor:
            cursor.execute("SELECT * FROM counts")
            return cursor.fetchall()

    def stat(self):
        tables = ['services']
        max_variables = 999  # SQLite maximum number of variables in a query

        # Switch to the second database to fetch filenames
        self.active_db = self.db_path_2
        for table in tables:
            with self.db_cursor() as cursor:
                cursor.execute(f"SELECT filenames FROM {table}")
                filenames_db2 = [row[0] for row in cursor.fetchall()]

            # Split the filenames into chunks
            filename_chunks = [filenames_db2[i:i + max_variables]
                               for i in range(0, len(filenames_db2), max_variables)]

            # Switch to the first database to fetch unique entries
            self.active_db = self.db_path_1
            unique_entries_count = 0
            for chunk in filename_chunks:
                with self.db_cursor() as cursor:
                    # Constructing query to fetch entries not in filenames from db2
                    query = f"SELECT * FROM {
                        table} WHERE filenames NOT IN ({', '.join('?' * len(chunk))})"
                    cursor.execute(query, chunk)
                    unique_entries = cursor.fetchall()
                    unique_entries_count += len(unique_entries)

            print(f"Table {table}: {
                len(unique_entries) + len(filenames_db2)}")

        # Reset active_db to default
        self.active_db = self.db_path_1

    def fetch_and_aggregate_summary_data(self):
        # Initialize a DataFrame to store the aggregated data
        aggregated_data = pd.DataFrame()

        # Fetch and translate data from both databases
        for db_path in [self.db_path_1, self.db_path_2]:
            self.active_db = db_path
            with self.db_cursor() as cursor:
                cursor.execute(
                    "SELECT country, unique_usernames, unique_passwords, \
                     unique_emails, unique_domains, unique_services \
                     FROM summary")
                results = cursor.fetchall()
                temp_df = pd.DataFrame(results, columns=[
                                       'country', 'unique_usernames', 'unique_passwords', 'unique_emails', 'unique_domains', 'unique_services'])

                # Translate country codes to full names
                temp_df['country'] = temp_df['country'].apply(
                    self.get_full_country_name)
                aggregated_data = pd.concat([aggregated_data, temp_df])

        # Group by full country name and sum the values
        aggregated_data = aggregated_data.groupby(
            'country').sum().reset_index()

        return aggregated_data.to_dict('records')

    @staticmethod
    def get_full_country_name(country_code):
        country = pycountry.countries.get(alpha_2=country_code)
        return country.name if country else "Unknown"

    def calculate_unique_entry(self):
        db_1 = []
        db_2 = []
        with self.db_cursor() as cursor:
            cursor.execute("SELECT filename FROM counts")
            db_1 = cursor.fetchall()
        self.switch_database()
        with self.db_cursor() as cursor:
            cursor.execute("SELECT filename FROM counts")
            db_2 = cursor.fetchall()

        unique_filename = set()
        for row in db_1:
            unique_filename.add(row[0])

        for row in db_2:
            unique_filename.add(row[0])

        unique_filename = list(unique_filename)
        print("DB Entry ", len(db_1), len(db_2),
              " total: ", len(db_1) + len(db_2))
        print("unique_filename ", len(unique_filename))

    def filter_service_x_count(self, filenames):
        max_variables = 999  # SQLite variable limit
        data = []

        # Function to split filenames into smaller batches
        def chunks(lst, n):
            for i in range(0, len(lst), n):
                yield lst[i:i + n]

        # Split filenames into batches and execute queries for each batch
        for batch in chunks(filenames, max_variables):
            with self.db_cursor() as cursor:
                sql_query = f'''
                    SELECT email_count, domains_count, username_count, password_count
                    FROM counts
                    WHERE filename IN ({",".join("?" * len(batch))})
                '''
                cursor.execute(sql_query, batch)
                data.extend(cursor.fetchall())

            # If you need to execute the same query in another database context
            # Make sure to switch databases appropriately and execute the query again
            self.switch_database()
            with self.db_cursor() as cursor:
                cursor.execute(sql_query, batch)
                data.extend(cursor.fetchall())

        return data

    def filter_service_x_domains(self, filenames):
        max_variables = 999  # SQLite variable limit
        data = []

        # Function to split filenames into smaller batches
        def chunks(lst, n):
            for i in range(0, len(lst), n):
                yield lst[i:i + n]

        # Split filenames into batches and execute queries for each batch
        for batch in chunks(filenames, max_variables):
            with self.db_cursor() as cursor:
                sql_query = f'''
                    SELECT domain
                    FROM domains
                    WHERE filenames IN ({",".join("?" * len(batch))})
                '''
                cursor.execute(sql_query, batch)
                data.extend(cursor.fetchall())

            # Assuming you need to switch databases and execute the query again
            self.switch_database()
            with self.db_cursor() as cursor:
                cursor.execute(sql_query, batch)
                data.extend(cursor.fetchall())

        return data


if __name__ == "__main__":
    from datetime import datetime
    starttime = datetime.now()
    sqlmanager = SqlManager()
    # sqlmanager.stat()
    # sqlmanager.switch_database()
    # data = sqlmanager.fetch_and_aggregate_summary_data()
    # print(len(data))
    # print(data[-1])
    # print(data[0])
    # print(data[1])
    # print(data[2])
    # data = sqlmanager.fetch_all_services()
    # print(data[-1])
    # print(data[0])
    # print(data[1])
    # print(data[2])
    print("Time diff: ", (datetime.now() - starttime))
